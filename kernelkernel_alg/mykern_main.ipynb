{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel density estimation and kernel regression for prediction\n",
    "This notebook is my first attempt to write down the ddiff and dddiff models that I have been working on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mixed recursive/iterative approach (rather than vectorized approach that is harder to generalize\n",
    "- create separate submodules for KDE and KDreg\n",
    "    - develop a system for storing differenced but unweighted data and the appropriate mask to lessen memory usage. \n",
    "        -1's or 0's depending on i/j/k/l/.... values\n",
    "    - figure out the deepest level requested by the user and levels that are less deep are just slices of the deeper model. \n",
    "        -scout out the tree to build the differenced dataset. \n",
    "          \n",
    "        \n",
    " plot and compare\n",
    "on synthetic data, 1, 2, 3+ mixed distributions\n",
    "1d - Ndiff vs gaussian kernel vs kernel_tunneling\n",
    "2d -  \n",
    "\n",
    "\n",
    "multidimensional x problem\n",
    "e.g., parameter treatment\n",
    "\"product kernel approach\" vs l2 \"el two\" (radial basis?)distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate a simple linear dataset y=xb+e\n",
    "##### store validation data from same dataset too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create modeldict\n",
    "- 'loss_function': \n",
    "  - 'mse'\n",
    "  - cross_mse\n",
    "  - cross_msei\n",
    "  - batch_crossval\n",
    "  - batchnorm_crossval\n",
    "- 'Ndiff_type': refers to the mathematical form of Ndiff\n",
    "  - 'product'-Ndiff1 multiplied by Ndiff2\n",
    "  - 'recursive'-Ndiff1's bw is Ndiff 2\n",
    "- max_bw_Ndiff: is the depth of Ndiffs applied in estimating the bandwidth.\n",
    "- 'normalize_Ndiffwtsum':\n",
    "  - 'across' means sum across own level of kernelized-Ndiffs and divide by that sum (CDF approach)\n",
    "  - 'own_n' means for (n+k)diff where n+K=max_bw_Ndiff\n",
    "- 'NWnorm\n",
    "  - 'across1' prior to 1/15 when mistake identified in summation dimension for NWnorm across\n",
    "  - 'across' correct implementation, where for each prediciton, the sum of the weights applied to the yout is normalized to 1.\n",
    "  - 'none'\n",
    "- Ndiff_bw_kern:\n",
    "  - rbfkern means use the radial basis function kernel\n",
    "  - 'product' means use product kernel like as in liu and yang eq1. \n",
    "- 'regression_model':\n",
    "  - 'NW' means use nadaraya-watson kernel regression\n",
    "  - 'NW-rbf' means use NW but calculate p(y,x) using rbf kernel rather than product kernel\n",
    "  - 'NW-rbf2' means NW-rbf plus euclidean distance logic (i.e. subtraction) for p(y,x)/p(y)\n",
    "  - 'full_logit' means local logit with all variables entering linearly\n",
    "  - 'rbf_logit' means local logit with 1 parameters: scaled l2 norm centered on zero \n",
    " (globally or by i?). Is this a new idea?\n",
    "- outer_x_bw_form: if x is separated into blocks of rvars that are combined within a block using rbf kernel, \n",
    "  - 'one_for_all' - use same hx bw for all blocks\n",
    "  - 'one_per_block' - each block or rvars gets an hx\n",
    "- ykerngrid_form\n",
    "  - ('even',4),then create 'ykern_grid' evnely spaced values from -4 to 4 \n",
    "  - ('exp',4), then create'ykern_grid' exponentially spaced (more near zero) values from -4 to 4\n",
    "  - ('binary_cont') a continuous spread of 'ykern_grid' values from 0 to 1, inclusive\n",
    "- ykern_grid\n",
    "  - 'no' means use original data points (self is masked when predicting self)\n",
    "  - an integer specifies the number of values to use in 'ykerngrid_form'\n",
    "- xkern_grid\n",
    "  - much like ykern_grid, but used less frequently since x's are typically pre-specified\n",
    "- product_kern_norm: when multiplying kernels across random variables, this parameter determines if each random variable has its kernels normalized before the product or not\n",
    "  - 'self' means each random variable has its kernels divided by the sum of kernels across the nout axis (the number of possibile values y is averaged over, whose probabilities sum to 1)\n",
    "  - 'own_n' means same as self, but divided by count of non-masked items in second to last, nout lenght dimension\n",
    "  - 'none' means no normalization prior to taking products across rvar kernels\n",
    "- hyper_param_form_dict is a nested dictionary\n",
    "  - Ndiff_exponent is the exponent wrapped around typically a sum of kernels for each Ndiff level \n",
    "after level 1 (i.e., (i-j) or centered, obvious/conventional level.)\n",
    "  - x_bandscale is the parameter specific to each variable (each x in X) used for prediction (y)\n",
    "  - Ndiff_depth_bw is used as the kernel's bandwidth (h) at each level of Ndiff including at level 1 \n",
    "  - outer_x_bw vanilla bandwidth for the rbf or product kernel\n",
    "  - outer_y_bw vanilla bandwidth for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import os\n",
    "import kernelcompare as kc\n",
    "#from importlib import reload\n",
    "networkdir='o:/public/dpatton/kernel'\n",
    "mydir=os.getcwd()\n",
    "#mydir2=os.path.join(mydir,\"old models without datagen\")\n",
    "test=kc.KernelCompare(directory=mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=32\n",
    "ykerngrid_form_variations=('modeldict:ykerngrid_form',[('exp',5),('even',5)])\n",
    "lossfn_variations=('modeldict:loss_function',['batchnorm_crossval'])\n",
    "#lossfn_variations=('modeldict:loss_function',['batch_crossval'])\n",
    "#lossfn_variations=('modeldict:loss_function',['mse'])\n",
    "#Ndiff_type_variations=('modeldict:Ndiff_type',['recursive'])\n",
    "Ndiff_type_variations=('modeldict:Ndiff_type',['product'])\n",
    "max_bw_Ndiff_variations=('modeldict:max_bw_Ndiff',[2])\n",
    "NWnorm_variations=('modeldict:NWnorm',['none'])\n",
    "Ndiff_start_variations=('modeldict:Ndiff_start',[1])\n",
    "ykern_grid_variations=('modeldict:ykern_grid',[n+1])\n",
    "#ykern_grid_variations=('modeldict:ykern_grid',['no'])\n",
    "regression_model_variations=('modeldict:regression_model',['NW-rbf'])\n",
    "#product_kern_norm_variations=('modeldict:product_kern_norm',['self','own_n'])#include None too?\n",
    "product_kern_norm_variations=('modeldict:product_kern_norm',[None])\n",
    "normalize_Ndiffwtsum_variations=('modeldict:normalize_Ndiffwtsum',['own_n'])#'across'\n",
    "optdict_variation_list=[NWnorm_variations,\n",
    "                        ykerngrid_form_variations, \n",
    "                        lossfn_variations,\n",
    "                        regression_model_variations,\n",
    "                        Ndiff_type_variations,\n",
    "                        ykern_grid_variations,\n",
    "                        max_bw_Ndiff_variations,Ndiff_start_variations\n",
    "                       ]  #,product_kern_norm_variations,normalize_Ndiffwtsum_variations]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the default datagen_dict as of 11/25/2019\n",
    "#datagen_dict={'batch_n':32,'batchcount':10, 'param_count':param_count,'seed':1, 'ftype':'linear', 'evar':1, 'source':'monte'}\n",
    "\n",
    "\n",
    "batch_n_variations=('batch_n',[n])\n",
    "batchcount_variations=('batchcount',[6])\n",
    "#ftype_variations=('ftype',['linear','quadratic'])\n",
    "ftype_variations=('ftype',['linear'])\n",
    "param_count_variations=('param_count',[4])\n",
    "#need to add block capability to datagen so we can repeat optimization with new training data.\n",
    "\n",
    "datagen_variation_list=[batch_n_variations,batchcount_variations,ftype_variations,param_count_variations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing monte carlo datagen_dict\n",
      "WARNING <PID 21080:MainProcess> myKernLogger.prep_model_list(): initializing monte carlo datagen_dict\n",
      "len(datagen_dict_list):1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'species'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bac2c129816a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestrun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprep_model_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptdict_variation_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptdict_variation_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatagen_variation_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen_variation_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m '''print(f'len(testrun){len(testrun)}')\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'testrun[0]{testrun[0:2]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m print(f'testrun[-1]{testrun[-4:]}')'''\n",
      "\u001b[1;32m~\\gits\\kernelkernel\\kernelcompare.py\u001b[0m in \u001b[0;36mprep_model_list\u001b[1;34m(self, optdict_variation_list, datagen_variation_list, datagen_dict, verbose)\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'len(datagen_dict_list):{len(datagen_dict_list)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0malt_datagen_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen_dict_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m             \u001b[0minitial_opt_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_optdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malt_datagen_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'param_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malt_datagen_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'species'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m             \u001b[0moptdict_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_dict_variations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_opt_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptdict_variation_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0moptdict_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptdict_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'species'"
     ]
    }
   ],
   "source": [
    "testrun=test.prep_model_list(optdict_variation_list=optdict_variation_list,datagen_variation_list=datagen_variation_list,verbose=1)\n",
    "'''print(f'len(testrun){len(testrun)}')\n",
    "print(f'testrun[0]{testrun[0:2]}')\n",
    "print('--------------')\n",
    "print(f'testrun[-1]{testrun[-4:]}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "#from random import shuffle\n",
    "#shuffle(testrun)\n",
    "testrun=testrun[-1::]\n",
    "#a_rundict=testrun[100]#this produced the Ndiff_exponent error for recursive Ndiff\n",
    "for idx in range(1):#len(testrun)):\n",
    "    print(f'~~~~~~~run number:{idx}`~~~~~~~')\n",
    "    a_rundict=testrun[idx]\n",
    "    print(f'a_rundict{a_rundict}')\n",
    "    optimizedict=a_rundict['optimizedict']\n",
    "    datagen_dict=a_rundict['datagen_dict']\n",
    "\n",
    "    try:\n",
    "        test.do_monte_opt(optimizedict,datagen_dict,force_start_params=0)\n",
    "        test.open_condense_resave('model_save',verbose=0)\n",
    "        test.merge_and_condense_saved_models(merge_directory=None,save_directory=None,condense=None,verbose=None)\n",
    "    except:\n",
    "        print('traceback for run',idx)\n",
    "        print(traceback.format_exc())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
